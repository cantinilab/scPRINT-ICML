{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "! lamin load jkobject/scprint"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Seed set to 42\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[92mâ†’\u001b[0m connected lamindb: jkobject/scprint2\n"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch import Trainer, seed_everything\n",
                        "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
                        "\n",
                        "seed_everything(42, workers=True)\n",
                        "\n",
                        "from scprint import scPrint\n",
                        "from scprint.trainer    import TrainingMode\n",
                        "from scdataloader import DataModule \n",
                        "import pandas as pd\n",
                        "from scdataloader.utils import load_genes\n",
                        "import lamindb as ln\n",
                        "\n",
                        "import torch\n",
                        "torch.set_float32_matmul_precision('medium')\n",
                        "\n",
                        "%load_ext autoreload\n",
                        "%autoreload 2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# TODO: drop tissue & dev stage until part or is taken in account\n",
                        "\n",
                        "hierarchical_clss = [\n",
                        "    \"cell_type_ontology_term_id\",  # 1\n",
                        "    \"tissue_ontology_term_id\",\n",
                        "    \"disease_ontology_term_id\",  # 2\n",
                        "    # \"development_stage_ontology_term_id\",\n",
                        "    \"assay_ontology_term_id\",  # 3\n",
                        "    'self_reported_ethnicity_ontology_term_id',  # 4\n",
                        "]\n",
                        "clss_to_predict = hierarchical_clss+[\n",
                        "    'sex_ontology_term_id',  # 5\n",
                        "    \"organism_ontology_term_id\",  # 6\n",
                        "    \"cell_culture\"\n",
                        "]\n",
                        "clss_to_weight = clss_to_predict+[\n",
                        "    # 'dataset_id',\n",
                        "    # 'cell_culture',\n",
                        "    #  \"heat_diff\",\n",
                        "    #  \"total_counts\",\n",
                        "    \"nnz\",\n",
                        "    #  \"dpt_group\",\n",
                        "]\n",
                        "\n",
                        "gene_emb = '../data/main/gene_embeddings.parquet'\n",
                        "d_model = 128"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[93m!\u001b[0m no run & transform got linked, call `ln.track()` & re-run\n",
                                    "\u001b[93m!\u001b[0m run input wasn't tracked, call `ln.track()` and re-run\n",
                                    "\u001b[93m!\u001b[0m run input wasn't tracked, call `ln.track()` and re-run\n",
                                    "won't do any check but we recommend to have your dataset coming from local storage\n",
                                    "100.0% are aligned\n",
                                    "seeing a string: loading gene positions as biomart parquet file\n"
                              ]
                        }
                  ],
                  "source": [
                        "datamodule = DataModule(\n",
                        "    collection_name=\"scPRINT-V2 test\", #some, all, preprocessed dataset, all no zhang, \n",
                        "    gene_embeddings=gene_emb,\n",
                        "    clss_to_weight=clss_to_weight,\n",
                        "    metacell_mode=True,\n",
                        "    clss_to_predict=clss_to_predict,\n",
                        "    hierarchical_clss=hierarchical_clss,\n",
                        "    organisms=[\"NCBITaxon:9606\"],#, \"NCBITaxon:10090\"],\n",
                        "    how=\"most expr\",\n",
                        "    max_len=3200,\n",
                        "    add_zero_genes=0,\n",
                        "    # how much more you will see the most present vs less present category\n",
                        "    weight_scaler=100,\n",
                        "    batch_size=10,\n",
                        "    num_workers=12,\n",
                        "    # train_oversampling=2,\n",
                        "    validation_split=0.05,\n",
                        "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
                        "    test_split=0.05)\n",
                        "testfiles = datamodule.setup()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# create a function to transform an scGPT checkpoint to an scPrint's\n",
                        "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
                        "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# from lightning.pytorch.profilers import PyTorchProfiler\n",
                        "# pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.save_pretrained(\"test\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "b911d78fb8384901bd66d59db8645dda",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "pytorch_model.bin:   0%|          | 0.00/120M [00:00<?, ?B/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "ename": "TypeError",
                              "evalue": "scPrint.__init__() missing 1 required positional argument: 'genes'",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscPrint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjkobject/scPRINT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint17/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint17/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:157\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    155\u001b[0m     model_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config})\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint17/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:362\u001b[0m, in \u001b[0;36mPyTorchModelHubMixin._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     model_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    352\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m    353\u001b[0m         filename\u001b[38;5;241m=\u001b[39mPYTORCH_WEIGHTS_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    361\u001b[0m     )\n\u001b[0;32m--> 362\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_file, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(map_location))\n\u001b[1;32m    365\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39mstrict)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
                                    "\u001b[0;31mTypeError\u001b[0m: scPrint.__init__() missing 1 required positional argument: 'genes'"
                              ]
                        }
                  ],
                  "source": [
                        "scPrint.push_to_hub(\"jkobject/scPRINT\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "'cuda'"
                                    ]
                              },
                              "execution_count": 7,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "model.device.type"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model = model.to(\"cuda\")\n",
                        "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
                        "    for batch in datamodule.train_dataloader():\n",
                        "        gene_pos, expression, depth = (batch[\"genes\"], batch[\"x\"], batch[\"depth\"])\n",
                        "        gene_pos, expression, depth = gene_pos.to(\"cuda\"), expression.to(\"cuda\"), depth.to(\"cuda\")\n",
                        "        res = model._predict(gene_pos, expression, depth)\n",
                        "        break\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model = scPrint(\n",
                        "    genes=datamodule.genes,\n",
                        "    d_model=d_model*2,\n",
                        "    nhead=4*2,\n",
                        "    num_heads_kv=2,\n",
                        "    nlayers=8,\n",
                        "    layers_cls = [d_model],\n",
                        "    classes = datamodule.classes,\n",
                        "    labels_hierarchy = datamodule.labels_hierarchy,\n",
                        "    dropout=0,\n",
                        "    transformer=\"flash\",\n",
                        "    precpt_gene_emb=gene_emb,\n",
                        "    gene_pos_enc=datamodule.gene_pos,\n",
                        "    mvc_decoder=\"inner product\",\n",
                        "    label_decoders = datamodule.decoders,\n",
                        "    fused_dropout_add_ln=False,\n",
                        "    num_batch_labels = datamodule.num_datasets,\n",
                        "    checkpointing=False,\n",
                        "    prenorm=True,\n",
                        "    #weight_decay=0.01,\n",
                        "    #zinb=False\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
                                    "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjkobject\u001b[0m (\u001b[33mml4ig\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Tracking run with wandb version 0.18.7"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Run data is saved locally in <code>../data/tensorboard/wandb/run-20241205_171025-0g3z31yt</code>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt' target=\"_blank\">clean-dragon-11</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
                              ]
                        }
                  ],
                  "source": [
                        "# from lightning.pytorch.loggers import TensorBoardLogger\n",
                        "from lightning.pytorch.loggers import WandbLogger\n",
                        "\n",
                        "wandb_logger = WandbLogger(project=\"scprint_test\",\n",
                        "                           save_dir=\"../data/tensorboard\")\n",
                        "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
                        "\n",
                        "# tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
                        "# tlogger.log_graph(model)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import gseapy as gp"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "tfchip = gp.get_library(name=\"ENCODE_TF_ChIP-seq_2014\")\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import json\n",
                        "\n",
                        "# Save the dictionary to a JSON file\n",
                        "with open('../data/tfchip_data.json', 'w') as file:\n",
                        "    json.dump(tfchip, file)\n",
                        "\n",
                        "# Load the dictionary back from the JSON file\n",
                        "with open('tfchip_data.json', 'r') as file:\n",
                        "    tfchip_loaded = json.load(file)\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
                        "trainingmode = TrainingMode(\n",
                        "    do_denoise=True,\n",
                        "    noise=[0.7],\n",
                        "    do_cce=False,\n",
                        "    cce_sim=0.6,\n",
                        "    do_ecs=False,\n",
                        "    ecs_threshold=0.4,\n",
                        "    ecs_scale=0.05,\n",
                        "    class_scale=0.08,\n",
                        "    do_cls=False,\n",
                        "    do_mvc=False,\n",
                        "    do_adv_cls=False,\n",
                        "    do_next_tp=False,\n",
                        "    mask_ratio=[\"TF\", 0.4],\n",
                        "    warmup_duration=100,\n",
                        "    fused_adam=True,\n",
                        "    lr_reduce_patience=200,\n",
                        ")\n",
                        "# es = EarlyStopping(patience=2, monitor='val_loss')\n",
                        "# swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
                        "# lrm = LearningRateMonitor(logging_interval=\"step\")\n",
                        "# lrf = LearningRateFinder(mode=\"exponential\",)\n",
                        "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
                        "# , logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, reload_dataloaders_every_n_epochs=1000000, \n",
                        "                  #logger=wandb_logger\n",
                        "                  )"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "# sanity. should be overfiting.\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, overfit_batches=1, \n",
                        "                  reload_dataloaders_every_n_epochs=1_000_000, logger=wandb_logger, num_sanity_val_steps=0)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "<torch.utils.data.dataloader.DataLoader at 0x7f41ad4d71c0>"
                                    ]
                              },
                              "execution_count": 10,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "\n",
                        "dataloader = datamodule.train_dataloader()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 23,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "(3000,)"
                                    ]
                              },
                              "execution_count": 23,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "dataloader.dataset.mapped_dataset[200000]['X'].shape\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                                    "\n",
                                    "  | Name                            | Type                         | Params | Mode \n",
                                    "-----------------------------------------------------------------------------------------\n",
                                    "0 | gene_encoder                    | GeneEncoder                  | 5.9 M  | train\n",
                                    "1 | expr_encoder                    | ContinuousValueEncoder       | 66.8 K | train\n",
                                    "2 | pos_encoder                     | PositionalEncoding           | 0      | train\n",
                                    "3 | class_encoder                   | CategoryValueEncoder         | 2.3 K  | train\n",
                                    "4 | depth_encoder                   | ContinuousValueEncoder       | 66.8 K | train\n",
                                    "5 | transformer                     | FlashTransformer             | 5.5 M  | train\n",
                                    "6 | expr_decoder                    | ExprDecoder                  | 133 K  | train\n",
                                    "7 | cls_decoders                    | ModuleDict                   | 278 K  | train\n",
                                    "8 | grad_reverse_discriminator_loss | AdversarialDiscriminatorLoss | 133 K  | train\n",
                                    "9 | mvc_decoder                     | MVCDecoder                   | 262 K  | train\n",
                                    "-----------------------------------------------------------------------------------------\n",
                                    "6.5 M     Trainable params\n",
                                    "5.9 M     Non-trainable params\n",
                                    "12.4 M    Total params\n",
                                    "49.592    Total estimated model params size (MB)\n",
                                    "241       Modules in train mode\n",
                                    "0         Modules in eval mode\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "ee14f3dfac2046599f394767c6beb2cd",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "ename": "IndexError",
                              "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ml4ig1/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ml4ig1/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/ml4ig1/Documents code/scDataLoader/scdataloader/collator.py\", line 144, in __call__\n    expr = expr[self.accepted_genes[organism_id]]\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 3000 but corresponding boolean dimension is 70704\n",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
                                    "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ml4ig1/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ml4ig1/Documents code/scPRINT/scprint2/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/ml4ig1/Documents code/scDataLoader/scdataloader/collator.py\", line 144, in __call__\n    expr = expr[self.accepted_genes[organism_id]]\nIndexError: boolean index did not match indexed array along dimension 0; dimension is 3000 but corresponding boolean dimension is 70704\n"
                              ]
                        }
                  ],
                  "source": [
                        "trainer.fit(model, datamodule=datamodule)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[93m!\u001b[0m run input wasn't tracked, call `ln.track()` and re-run\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/plain": [
                                          "AnnDataAccessor object with n_obs Ã— n_vars = 71735 Ã— 3000\n",
                                          "  constructed for the AnnData object GcVBvpW5MYlrsH1izOjO.h5ad\n",
                                          "    layers: ['norm']\n",
                                          "    obs: ['G2M_score', 'S_score', '_index', 'assay', 'assay_ontology_term_id', 'batch', 'batches', 'bh_pval', 'big_cluster', 'broad_celltype', 'cell_culture', 'cell_type', 'cell_type_ontology_term_id', 'chemistry', 'development_stage', 'development_stage_ontology_term_id', 'disease', 'disease_ontology_term_id', 'dissection', 'donor_id', 'doublet_scores', 'is_primary_data', 'leiden', 'leiden_0.5', 'leiden_1', 'leiden_2', 'log1p_n_genes_by_counts', 'log1p_total_counts', 'log1p_total_counts_hb', 'log1p_total_counts_mt', 'log1p_total_counts_ribo', 'mt_outlier', 'n_counts', 'n_genes', 'n_genes_by_counts', 'new_celltype', 'nnz', 'observation_joinid', 'organism', 'organism_ontology_term_id', 'outlier', 'pct_counts_hb', 'pct_counts_in_top_20_genes', 'pct_counts_mt', 'pct_counts_ribo', 'percent_mito', 'phase', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'sex', 'sex_ontology_term_id', 'suspension_type', 'tissue', 'tissue_ontology_term_id', 'tissue_type', 'total_counts', 'total_counts_hb', 'total_counts_mt', 'total_counts_ribo']\n",
                                          "    obsm: ['X_pca', 'X_umap']\n",
                                          "    obsp: ['connectivities', 'distances']\n",
                                          "    uns: ['batches_colors', 'cell_type_colors', 'dataset_id', 'hvg', 'leiden_0.5', 'leiden_1', 'leiden_2', 'log1p', 'neighbors', 'pca', 'umap', 'unseen_genes']\n",
                                          "    var: ['_index', 'biotype', 'description', 'feature_biotype', 'feature_is_filtered', 'feature_length', 'feature_name', 'feature_reference', 'gene_symbols', 'hb', 'highly_variable', 'highly_variable_nbatches', 'highly_variable_rank', 'log1p_mean_counts', 'log1p_total_counts', 'mean_counts', 'means', 'mt', 'n_cells', 'n_cells_by_counts', 'ncbi_gene_ids', 'organism', 'organism_id', 'pct_dropout_by_counts', 'ribo', 'symbol', 'synonyms', 'total_counts', 'uid', 'variances', 'variances_norm']\n",
                                          "    varm: ['PCs']"
                                    ]
                              },
                              "execution_count": 16,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ln.Collection.filter(name=\"scPRINT-V2 test\").one().artifacts.filter().first().open()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "from scprint.tasks.grn import default_benchmark"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr_reduce_patience = 50\n",
                        "model.lr_reduce_ratio = 0.2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr = 0.00001"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:515: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=adata.obs['organism_ontology_term_id'][0],\n",
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:167: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=[subadata.obs['organism_ontology_term_id'][0]],\n",
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "e98d671466dc4343b9e21418751bc904",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Predicting: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "avg link count: 536246649, sparsity: 1.0\n",
                                    "base enrichment\n",
                                    "too many genes for central computation\n",
                                    "_________________________________________\n",
                                    "TF specific enrichment\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-22 13:16:10,303:INFO - Downloading and generating Enrichr library gene sets...\n",
                                    "2024-05-22 13:16:10,305:INFO - Library is already downloaded in: /home/ml4ig1/.cache/gseapy/Enrichr.ENCODE_TF_ChIP-seq_2014.gmt, use local file\n",
                                    "2024-05-22 13:16:10,530:INFO - 0332 gene_sets have been filtered out when max_size=2000 and min_size=0\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "found some significant results for  7.142857142857143 % TFs\n",
                                    "\n",
                                    "_________________________________________\n",
                                    "loading GT,  omnipath\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:109: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  da = np.zeros(adj.shape, dtype=np.float)\n",
                                    " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 98/99 [00:26<00:00,  3.76it/s]/home/ml4ig1/Documents code/benGRN/bengrn/base.py:683: RuntimeWarning: invalid value encountered in long_scalars\n",
                                    "  precision_list.append(precision)\n",
                                    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:26<00:00,  3.74it/s]\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:532: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=adata.obs['organism_ontology_term_id'][0],\n",
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n",
                                    "WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:167: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=[subadata.obs['organism_ontology_term_id'][0]],\n",
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "6efb9f25b0e24313a1b02f7cc939b638",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Predicting: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:277: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  if i in genes and j in genes:\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "true elem 14408 ...\n",
                                    "doing regression....\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:303: RuntimeWarning: invalid value encountered in long_scalars\n",
                                    "  \"recall\": (pred[y_test == 1] == 1).sum() / y_test.sum(),\n"
                              ]
                        },
                        {
                              "ename": "ValueError",
                              "evalue": "too many values to unpack (expected 2)",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdefault_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/yBCKp6HmXuHa0cZptMo7.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#gwps, other\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/grn.py:539\u001b[0m, in \u001b[0;36mdefault_benchmark\u001b[0;34m(model, default_dataset, cell_types, maxlayers, maxgenes)\u001b[0m\n\u001b[1;32m    526\u001b[0m grn_inferer \u001b[38;5;241m=\u001b[39m GRNfer(model, adata[adata\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m],\n\u001b[1;32m    527\u001b[0m                      how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost var across\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m                      preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m                      batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    537\u001b[0m                      )\n\u001b[1;32m    538\u001b[0m grn \u001b[38;5;241m=\u001b[39m grn_inferer(layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mnlayers))[:], cell_type\u001b[38;5;241m=\u001b[39mcelltype)\n\u001b[0;32m--> 539\u001b[0m grn, m \u001b[38;5;241m=\u001b[39m train_classifier(grn, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    540\u001b[0m                           \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1\u001b[39m}, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, doplot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m grn\u001b[38;5;241m.\u001b[39mvarp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grn\u001b[38;5;241m.\u001b[39mvarp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassified\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    542\u001b[0m grn\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m make_index_unique(grn\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))\n",
                                    "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
                              ]
                        },
                        {
                              "ename": "",
                              "evalue": "",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                                    "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                                    "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                                    "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                              ]
                        }
                  ],
                  "source": [
                        "default_benchmark(model, default_dataset=\"../data/yBCKp6HmXuHa0cZptMo7.h5ad\") #gwps, other"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "weirdly, when input expression is set to 0 and pi is set to 1000. I get a loss of 0\n",
                        "when input expression is set to some set of values and pi=-10, disp=max, mean=input, I get 0.479, decreasing pi doesn't help, making it higher, makes it worse, max of disp is ~3M afterward it increases back (likely due to some overflow??). I am guessing that it would need to be set to infinity for it to work. might be better to use dispersion instead of inverse dispersion?\n",
                        "\n",
                        "all things equal, if disp is set to 2_700_000, I get loss tensor(3.8694, device='cuda:0')\n",
                        "if disp is 2_700_000+1 -> tensor(0.1994, device='cuda:0')\n",
                        "\n",
                        "basically it seems that at too high values or at too low values we get strong instabilities that are exacerbated by the fact that we are in float16.\n",
                        "could it also be because of the espilon? nope\n",
                        "\n",
                        "-> why doesn't my model go to this low loss value??\n",
                        "\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "1. there seems to be an in-between value of disp that makes sense given the expression data\n",
                        "2. "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import torch.nn.functional as F"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "F.mse_loss(expression, expression, reduction=\"mean\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=disp,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"] + 10000,\n",
                        "    pi=output[\"zero_logits\"]-3,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ").mean()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "expr = expression.clone()\n",
                        "expr[:,-20:] = 0\n",
                        "expr[:,:20] +=1"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*output[\"mean\"]/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*expr/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "exp(15)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "disp = torch.zeros_like(output[\"disp\"])\n",
                        "pi = torch.zeros_like(output[\"disp\"]) - 10"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# why if it is the inverse dispersion? does setting it to 3_000_000 works but not 10_000_000?\n",
                        "# maybe some overflow??"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%reload_ext tensorboard\n",
                        "%tensorboard --logdir=\"../data/tensorboard\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# wandb_logger.finalize(status=\"aborted\")\n",
                        "torch.cuda.empty_cache()"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "scprint",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.10.15"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
